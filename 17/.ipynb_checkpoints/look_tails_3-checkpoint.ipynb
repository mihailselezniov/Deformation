{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, average_precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.externals import joblib\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import collections\n",
    "\n",
    "\n",
    "ex_name = '13_1_mlp_4.txt'\n",
    "ppl = [0.8, 0.9]# predict_proba_limits\n",
    "folder_name = 'ml_threads/'\n",
    "f_name = folder_name + ex_name\n",
    "\n",
    "par = {}\n",
    "parts = 10\n",
    "parts4 = 100\n",
    "par['pressure_time'] = {'Min': 0.0, 'Max': 100.0}\n",
    "par['pressure_radius'] = {'Min': 0.0, 'Max': 5.0}\n",
    "par['pressure_amplitude'] = {'Min': 0.0, 'Max': 200.0}\n",
    "par['length'] = {'Min': 10.0, 'Max': 100.0}\n",
    "par['diameter'] = {'Min': 0.01, 'Max': 0.5}\n",
    "par['young'] = {'Min': 60.0, 'Max': 300.0}\n",
    "par['density'] = {'Min': 1000.0, 'Max': 2000.0}\n",
    "par['strength'] = {'Min': 0.2, 'Max': 10.0}\n",
    "order_par = ['length', 'diameter', 'young', 'density', 'pressure_time', 'pressure_radius', 'pressure_amplitude', 'strength']\n",
    "\n",
    "def get_list(Min, Max):\n",
    "    return list(map(lambda x: round(x, 2), np.arange(Min, Max+0.01, (Max-Min)/(parts-1))))\n",
    "\n",
    "def get_list4(Min, Max):\n",
    "    return list(map(lambda x: round(x, 4), np.arange(Min, Max+0.01, (Max-Min)/(parts4-1))))\n",
    "\n",
    "def get_raw(par_inxs):\n",
    "    return [get_list4(**par[par_name])[par_inxs[pi]] for pi, par_name in enumerate(order_par)]\n",
    "\n",
    "#print(get_list(**{'Min': 0, 'Max': 1}))\n",
    "\n",
    "e0 = tuple(enumerate(get_list(**par['length'])))\n",
    "e1 = tuple(enumerate(get_list(**par['diameter'])))\n",
    "e2 = tuple(enumerate(get_list(**par['young'])))\n",
    "e3 = tuple(enumerate(get_list(**par['density'])))\n",
    "e4 = tuple(enumerate(get_list(**par['pressure_time'])))\n",
    "e5 = tuple(enumerate(get_list(**par['pressure_radius'])))\n",
    "e6 = tuple(enumerate(get_list(**par['pressure_amplitude'])))\n",
    "e7 = tuple(enumerate(get_list(**par['strength'])))\n",
    "\n",
    "\n",
    "\n",
    "extreme_values = [[\n",
    "        par['length']['Min'],\n",
    "        par['diameter']['Min'],\n",
    "        par['young']['Min'],\n",
    "        par['density']['Min'],\n",
    "        par['pressure_time']['Min'],#get_list(**par['pressure_time'])[1],\n",
    "        par['pressure_radius']['Min'],#get_list(**par['pressure_radius'])[1],\n",
    "        par['pressure_amplitude']['Min'],#get_list(**par['pressure_amplitude'])[1],\n",
    "        par['strength']['Min'],\n",
    "        ],\n",
    "        [\n",
    "        par['length']['Max'],\n",
    "        par['diameter']['Max'],\n",
    "        par['young']['Max'],\n",
    "        par['density']['Max'],\n",
    "        par['pressure_time']['Max'],\n",
    "        par['pressure_radius']['Max'],\n",
    "        par['pressure_amplitude']['Max'],\n",
    "        par['strength']['Max'],\n",
    "        ]\n",
    "    ]\n",
    "extreme_values = np.array(extreme_values)\n",
    "#x_train = (x_train - extreme_values.min(axis=0)) / (extreme_values.max(axis=0) - extreme_values.min(axis=0))\n",
    "\n",
    "\n",
    "with open('../15/data3k_2.txt', 'r') as f:\n",
    "    data_is_broken = f.readlines()\n",
    "data_is_broken = list(map(int, data_is_broken))\n",
    "\n",
    "y_test = []\n",
    "for i, val in enumerate(data_is_broken):\n",
    "    y_test.extend([i%2]*val)\n",
    "\n",
    "\n",
    "new_parts = 19\n",
    "def get_new_list(Min, Max):\n",
    "    return list(map(lambda x: round(x, 2), np.arange(Min, Max+0.01, (Max-Min)/(new_parts-1))))[1::2]\n",
    "\n",
    "e2_0 = tuple(enumerate(get_new_list(**par['length'])))\n",
    "e2_1 = tuple(enumerate(get_new_list(**par['diameter'])))\n",
    "e2_2 = tuple(enumerate(get_new_list(**par['young'])))\n",
    "e2_3 = tuple(enumerate(get_new_list(**par['density'])))\n",
    "e2_4 = tuple(enumerate(get_new_list(**par['pressure_time'])))\n",
    "e2_5 = tuple(enumerate(get_new_list(**par['pressure_radius'])))\n",
    "e2_6 = tuple(enumerate(get_new_list(**par['pressure_amplitude'])))\n",
    "e2_7 = tuple(enumerate(get_new_list(**par['strength'])))\n",
    "\n",
    "x_test = []\n",
    "for i0, l in e2_0:\n",
    "    for i1, di in e2_1:\n",
    "        for i2, y in e2_2:\n",
    "            for i3, de in e2_3:\n",
    "                for i4, pt in e2_4:\n",
    "                    for i5, pr in e2_5:\n",
    "                        for i6, pa in e2_6:\n",
    "                            for i7, s in e2_7:\n",
    "                                #if 0 not in [i4, i5, i6]:\n",
    "                                #print(l, di, y, de, pt, pr, pa, s)\n",
    "                                x_test.append([l, di, y, de, pt, pr, pa, s])\n",
    "    print(i0)\n",
    "x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "\n",
    "x_test = (x_test - extreme_values.min(axis=0)) / (extreme_values.max(axis=0) - extreme_values.min(axis=0))\n",
    "\n",
    "\n",
    "def make_str(data):\n",
    "    return ''.join(map(str, data))\n",
    "def make_set(data):\n",
    "    return {make_str(i) for i in data}\n",
    "\n",
    "with open(f_name, 'r') as f:\n",
    "    threads = f.readlines()\n",
    "\n",
    "roc_metrics, pr_metrics, f1_metrics = [], [], []\n",
    "roc_metric, pr_metric, f1_metric = [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 500\n",
    "print('\\n\\n\\n', '#'*10, cut, '#'*10)\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for t in threads[:cut]:\n",
    "    tr = list(map(int, t.replace('\\n', '').split(',')))\n",
    "    x_train.append(tr[:-1])\n",
    "    y_train.append(tr[-1])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "x_train = np.array(list(map(get_raw, x_train)))\n",
    "x_train = (x_train - extreme_values.min(axis=0)) / (extreme_values.max(axis=0) - extreme_values.min(axis=0))\n",
    "model = MLPClassifier(activation='tanh', solver='adam', hidden_layer_sizes=(70, 70, 70), max_iter=100000, random_state=42)\n",
    "print('\\n', '-'*10, model.__class__.__name__, '-'*10)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print('y_test', dict(collections.Counter(y_test)), 'y_train', dict(collections.Counter(y_train)))\n",
    "# fit model on training data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test[:10000000])\n",
    "y_pred = np.concatenate((y_pred, model.predict(x_test[10000000:20000000])))\n",
    "y_pred = np.concatenate((y_pred, model.predict(x_test[20000000:30000000])))\n",
    "y_pred = np.concatenate((y_pred, model.predict(x_test[30000000:40000000])))\n",
    "y_pred = np.concatenate((y_pred, model.predict(x_test[40000000:])))\n",
    "\n",
    "\n",
    "y_pred_proba = model.predict_proba(x_test[:10000000])\n",
    "y_pred_proba = np.concatenate((y_pred_proba, model.predict_proba(x_test[10000000:20000000])))\n",
    "y_pred_proba = np.concatenate((y_pred_proba, model.predict_proba(x_test[20000000:30000000])))\n",
    "y_pred_proba = np.concatenate((y_pred_proba, model.predict_proba(x_test[30000000:40000000])))\n",
    "y_pred_proba = np.concatenate((y_pred_proba, model.predict_proba(x_test[40000000:])))\n",
    "y_pred_proba = y_pred_proba[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tail = y_pred_proba[y_test != y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(y_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_series = pd.Series(y_tail)\n",
    "y_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = y_pred_proba[y_test == y_pred]\n",
    "sns.distplot(y_main)\n",
    "y_main_series = pd.Series(y_main)\n",
    "y_main_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = y_pred_proba[(y_test == 1) & (y_test != y_pred)]\n",
    "sns.distplot(y_main)\n",
    "y_main_series = pd.Series(y_main)\n",
    "y_main_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = y_pred_proba[(y_test == 0) & (y_test != y_pred)]\n",
    "sns.distplot(y_main)\n",
    "y_main_series = pd.Series(y_main)\n",
    "y_main_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = np.round(y_pred_proba[(y_test == 0) & (y_test != y_pred)]*2, 1)*100\n",
    "sns.distplot(y_main)\n",
    "y_main_series = pd.Series(y_main)\n",
    "y_main_series.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
