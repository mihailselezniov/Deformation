import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, average_precision_score
from xgboost import XGBClassifier, XGBRegressor
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.svm import LinearSVC, SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.externals import joblib
import collections
import math
import sys
import time
import pickle
from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)

f_name = 'ml_threads/5_1.txt'



X = joblib.load('border_vars/X.j')
print('X')
Y = joblib.load('border_vars/Y.j')
print('Y')

#print(sys.getsizeof(way_dict))
print(X.shape, Y.shape)
print('all', dict(collections.Counter(Y)))


def fit_model(model):
    #print('-'*10, model.__class__.__name__, '-'*10)
    model.fit(x_train, y_train)
    return model.predict(X)
    '''
    try:
        return model.predict(X)
    except:
        #print('Error')
        pass
    return [0]*len(X)
    '''


#x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.0001, random_state=42)
while 1:
    with open(f_name, 'r') as f:
        threads = f.readlines()

    x_train, y_train = [], []
    for t in threads:
        tr = list(map(int, t.replace('\n', '').split(',')))
        x_train.append(tr[:-1])
        y_train.append(tr[-1])
    x_train, y_train = np.array(x_train), np.array(y_train)

    print('#', len(threads), 'y_train', dict(collections.Counter(y_train)))

    y_preds = []
    y_preds.append(fit_model(XGBClassifier()))
    y_preds.append(fit_model(LogisticRegression()))
    y_preds.append(fit_model(LinearSVC(random_state=0, tol=1e-5)))
    #y_preds.append(fit_model(KNeighborsClassifier(n_neighbors=5)))
    y_preds.append(fit_model(SGDClassifier()))
    y_preds.append(fit_model(BernoulliNB()))
    y_preds.append(fit_model(RandomForestClassifier()))
    #y_preds.append(fit_model(MLPClassifier()))
    y_preds.append(fit_model(SVC()))# Radial basis function kernel


    y_pred = [sum(i) for i in zip(*y_preds)]
    d_pred = dict(collections.Counter(y_pred))
    min_sum = min(list(d_pred))
    print('y_pred', d_pred, min_sum)

    threads_arr = {
        1: [list(x_train[i]) for i in range(len(x_train)) if y_train[i] == 1],
        0: [list(x_train[i]) for i in range(len(x_train)) if y_train[i] == 0]
    }

    result_dis, result_dis_1, result_id = 0, 0, 0
    for tid, i in enumerate(y_pred):
        if i != min_sum:
            continue
        l0 = list(X[tid])
        dis = min([sum(map(lambda x: (x[0] - x[1])**2, zip(thread, l0))) for thread in threads_arr[0]])
        if dis == result_dis:
            dis1 = min([sum(map(lambda x: (x[0] - x[1])**2, zip(thread, l0))) for thread in threads_arr[1]])
            if dis1 > result_dis_1:
                result_dis_1 = dis1
                result_dis = dis
                result_id = tid
        if dis > result_dis:
            result_dis_1 = min([sum(map(lambda x: (x[0] - x[1])**2, zip(thread, l0))) for thread in threads_arr[1]])
            result_dis = dis
            result_id = tid

    print(result_dis, result_dis_1, result_id, Y[result_id])
    row_data = list(X[result_id]) + [int(Y[result_id])]
    row_thread = ','.join(list(map(lambda x: str(int(x)), row_data)))
    print(row_thread)
    with open(f_name, 'a') as f:
        f.write(row_thread + '\n')


'''
(72900000, 8) (72900000,)
all {1: 63518691, 0: 9381309}
# 2 y_train {1: 1, 0: 1}
y_pred {6: 560, 5: 173089, 4: 4950122, 3: 15442037, 2: 36092273, 1: 15813015, 0: 428904} 0
184 252 7233319 0
0,9,9,2,3,1,2,9,0
# 3 y_train {1: 1, 0: 2}
y_pred {6: 7, 5: 180, 4: 10462, 3: 472291, 2: 28638980, 1: 39523465, 0: 4254615} 0
193 269 66273849 1
9,0,9,1,1,6,1,9,1
# 4 y_train {1: 2, 0: 2}
y_pred {6: 405787, 5: 4162984, 4: 17895552, 3: 22503134, 2: 10423484, 1: 14798566, 0: 2710493} 0
179 307 6626699 1
0,9,0,9,1,1,9,9,1
# 5 y_train {1: 3, 0: 2}
y_pred {7: 5949442, 6: 20606026, 5: 19748755, 4: 16194751, 3: 8165406, 2: 2226518, 1: 9102} 1
8 227 71874542 0
9,8,5,9,4,1,1,2,0
# 6 y_train {1: 3, 0: 3}
y_pred {6: 3086349, 5: 28994423, 4: 20910741, 3: 11956201, 2: 5810027, 1: 2035573, 0: 106686} 0
20 219 70265893 0
9,6,3,8,7,1,2,3,0
# 7 y_train {1: 3, 0: 4}
y_pred {6: 10301, 5: 1143168, 4: 12951426, 3: 27858301, 2: 14909867, 1: 10730570, 0: 5296367} 0
168 217 8018199 1
1,0,9,9,9,1,1,9,1
# 8 y_train {1: 4, 0: 4}
y_pred {7: 962087, 6: 6558515, 5: 21804527, 4: 20522883, 3: 11466289, 2: 7246103, 1: 4129584, 0: 210012} 0
24 222 70198121 1
9,6,2,9,4,4,2,1,1
# 9 y_train {1: 5, 0: 4}
y_pred {7: 7018397, 6: 23904425, 5: 31015858, 4: 4181155, 3: 3545033, 2: 3193703, 1: 41429} 1
18 48 57288875 0
7,8,5,8,6,1,1,5,0
# 10 y_train {1: 5, 0: 5}
y_pred {7: 5619476, 6: 24471249, 5: 23195311, 4: 11314670, 3: 3607290, 2: 3038677, 1: 1557555, 0: 95772} 0
24 48 71190113 0
9,7,6,5,5,1,3,3,0
# 11 y_train {1: 5, 0: 6}
y_pred {7: 6300945, 6: 26892914, 5: 19483907, 4: 9462583, 3: 4797926, 2: 3444482, 1: 2011911, 0: 505332} 0
34 72 43573163 0
5,9,7,7,2,1,3,3,0
# 12 y_train {1: 5, 0: 7}
y_pred {7: 17019, 6: 6923680, 5: 29400136, 4: 18702622, 3: 7342014, 2: 3605686, 1: 3761679, 0: 3147164} 0
169 130 13864045 1
1,9,0,1,8,1,9,5,1
# 13 y_train {1: 6, 0: 7}
y_pred {7: 8226788, 6: 18066652, 5: 22157708, 4: 16785320, 3: 2357515, 2: 2017002, 1: 2367404, 0: 921611} 0
37 53 50655022 0
6,9,4,8,6,1,6,2,0
# 14 y_train {1: 6, 0: 8}
y_pred {7: 60627, 6: 10609476, 5: 31222740, 4: 16348474, 3: 7555982, 2: 2532996, 1: 2809948, 0: 1759757} 0
118 163 5780260 1
0,7,9,2,9,2,2,0,1
# 15 y_train {1: 7, 0: 8}
y_pred {7: 11025365, 6: 31196648, 5: 14650053, 4: 8452910, 3: 2949290, 2: 1991723, 1: 1664118, 0: 969893} 0
37 53 47235182 0
6,4,7,9,5,1,4,2,0
# 16 y_train {1: 7, 0: 9}
y_pred {7: 46548, 6: 4061004, 5: 23795994, 4: 18391430, 3: 18052462, 2: 2799515, 1: 2935363, 0: 2817684} 0
145 114 64888379 1
8,9,0,1,1,1,9,9,1
# 17 y_train {1: 8, 0: 9}
y_pred {7: 9788289, 6: 24115193, 5: 19865054, 4: 11513000, 2: 1766754, 3: 2814368, 1: 1776762, 0: 1260580} 0
37 80 57510021 0
7,8,8,8,9,1,3,1,0
# 18 y_train {1: 8, 0: 10}
y_pred {7: 82073, 6: 6816840, 5: 15242598, 4: 22090682, 3: 24026874, 2: 1254327, 1: 1755743, 0: 1630863} 0
115 56 8538210 1
1,1,7,1,3,1,1,0,1
# 19 y_train {1: 9, 0: 10}
y_pred {7: 11683804, 6: 24972957, 4: 15202102, 5: 15860269, 3: 2143193, 2: 1051273, 1: 1118133, 0: 868269} 0
37 90 57514196 0
7,8,8,9,5,2,6,6,0
# 20 y_train {1: 9, 0: 11}
y_pred {7: 214175, 6: 10189196, 5: 20988484, 4: 17224138, 3: 14468872, 2: 6415792, 1: 1250520, 0: 2148823} 0
109 44 45154269 0
6,1,9,4,1,1,1,9,0
# 21 y_train {1: 9, 0: 12}
y_pred {7: 54208, 6: 7648557, 5: 19832237, 4: 19479518, 3: 21251277, 2: 961207, 1: 1413454, 0: 2259542} 0
107 88 72827259 0
9,9,9,0,1,2,7,9,0
# 22 y_train {1: 9, 0: 13}
y_pred {7: 20656, 6: 5451544, 5: 15553138, 4: 20331265, 3: 24198520, 2: 2821999, 1: 1446718, 0: 3076160} 0
99 74 50388669 0
6,9,1,2,1,3,1,9,0
# 23 y_train {1: 9, 0: 14}
y_pred {7: 12764, 6: 6639049, 5: 13637094, 4: 22145396, 3: 24947429, 2: 1004928, 1: 1291263, 0: 3222077} 0
107 17 30260790 1
4,1,5,1,1,1,1,0,1
# 24 y_train {1: 10, 0: 14}
y_pred {7: 57637, 6: 11747543, 5: 20795537, 4: 18739536, 3: 17074804, 2: 1345398, 1: 2205966, 0: 933579} 0
88 89 6918489 0
0,9,4,9,1,4,1,9,0
# 25 y_train {1: 10, 0: 15}
y_pred {7: 39056, 6: 11759503, 5: 15760521, 4: 18258820, 3: 22163938, 2: 1012400, 1: 1641606, 0: 2264156} 0
116 40 14149082 0
1,9,4,0,9,1,1,2,0
# 26 y_train {1: 10, 0: 16}
y_pred {7: 10097, 6: 11475332, 5: 9505049, 4: 17602156, 3: 18693690, 2: 10751758, 1: 1618996, 0: 3242922} 0
103 150 72833859 0
9,9,9,0,9,4,1,9,0
# 27 y_train {1: 10, 0: 17}
y_pred {7: 17330, 6: 11357829, 5: 17515940, 4: 18950906, 3: 19907108, 2: 1549250, 1: 2275686, 0: 1325951} 0
88 66 6560289 0
0,8,9,9,9,2,1,9,0
# 28 y_train {1: 10, 0: 18}
y_pred {7: 6126, 6: 9746250, 5: 17488740, 4: 17247011, 3: 12605562, 2: 10712019, 1: 1519553, 0: 3574739} 0
96 66 67067289 0
9,1,9,9,9,2,1,9,0
# 29 y_train {1: 10, 0: 19}
y_pred {7: 9034, 6: 8727474, 5: 10787111, 4: 23294140, 3: 21597605, 2: 3294415, 1: 1994682, 0: 3195539} 0
99 76 72265019 1
9,9,1,2,9,1,6,9,1
# 30 y_train {1: 11, 0: 19}
y_pred {7: 16555, 6: 11228672, 5: 19018943, 4: 18222791, 3: 18643933, 2: 1131861, 1: 1383786, 0: 3253459} 0
90 107 72871389 0
9,9,9,6,1,7,1,9,0
# 31 y_train {1: 11, 0: 20}
y_pred {7: 13555, 6: 13173983, 5: 17567217, 4: 15637422, 3: 20825492, 2: 1268489, 1: 1539962, 0: 2873880} 0
87 132 72827551 0
9,9,9,0,1,6,1,1,0
# 32 y_train {1: 11, 0: 21}
y_pred {7: 8754, 6: 11445716, 5: 12294278, 4: 21375053, 3: 19198576, 2: 2894168, 1: 1881681, 0: 3801774} 0
97 99 7217161 0
0,9,9,0,1,1,7,1,0
# 33 y_train {1: 11, 0: 22}
y_pred {7: 5788, 6: 9354856, 5: 11741217, 4: 21126786, 3: 19793400, 2: 4833389, 1: 1897690, 0: 4146874} 0
91 8 38199602 0
5,2,4,0,1,1,1,2,0
# 34 y_train {1: 11, 0: 23}
y_pred {7: 2138, 6: 11819519, 5: 19037912, 3: 17683354, 4: 12510179, 2: 5910197, 1: 1905356, 0: 4031345} 0
90 132 72681380 1
9,9,7,0,1,1,9,0,1
# 35 y_train {1: 12, 0: 23}
y_pred {7: 6942, 6: 13170262, 5: 9150465, 4: 14154836, 3: 29625110, 2: 1041994, 1: 1369199, 0: 4381192} 0
91 120 37317609 1
5,1,1,9,1,2,1,9,1
# 36 y_train {1: 13, 0: 23}
y_pred {7: 11900, 6: 13397331, 5: 14000832, 4: 8096269, 3: 31375081, 2: 1188968, 1: 1483784, 0: 3345835} 0
85 66 24734167 0
3,3,9,2,9,1,1,7,0
# 37 y_train {1: 13, 0: 24}
y_pred {7: 8374, 6: 15564002, 5: 12736736, 4: 6158499, 3: 32062975, 2: 1313669, 1: 982456, 0: 4073289} 0
87 82 7275509 0
0,9,9,8,1,1,9,9,0
# 38 y_train {1: 13, 0: 25}
y_pred {7: 6487, 6: 12160185, 5: 10471583, 4: 12658676, 3: 29347559, 2: 2475392, 1: 1649642, 0: 4130476} 0
85 57 1735024 0
0,2,3,8,1,1,1,4,0
# 39 y_train {1: 13, 0: 26}
y_pred {7: 5001, 6: 5350499, 5: 13479262, 4: 14452631, 3: 33243819, 2: 1381275, 1: 1843909, 0: 3143604} 0
85 45 54768969 0
7,5,1,2,9,1,1,9,0
# 40 y_train {1: 13, 0: 27}
y_pred {7: 3016, 6: 10592248, 5: 8987657, 4: 12323457, 3: 27317024, 2: 7780573, 1: 1503642, 0: 4392383} 0
82 89 4664791 0
0,6,3,9,9,1,1,1,0
# 41 y_train {1: 13, 0: 28}
y_pred {7: 3510, 6: 8666772, 5: 12337444, 4: 14142493, 3: 23557570, 2: 7905608, 1: 1833983, 0: 4452620} 0
88 96 6655951 1
0,9,1,3,1,3,1,1,1
# 42 y_train {1: 14, 0: 28}
y_pred {7: 5372, 6: 10815737, 5: 12159627, 4: 10398784, 3: 33164180, 2: 1181117, 1: 1107909, 0: 4067274} 0
78 101 67657681 0
9,2,8,0,9,1,1,1,0
# 43 y_train {1: 14, 0: 29}
y_pred {7: 5109, 6: 9987961, 5: 14070187, 4: 10916532, 3: 31958298, 2: 1152083, 1: 1539172, 0: 3270658} 0
76 99 2405709 0
0,3,3,0,1,1,1,9,0
# 44 y_train {1: 14, 0: 30}
y_pred {7: 3510, 6: 12459654, 5: 12727110, 4: 8653731, 3: 27435911, 2: 5906134, 1: 1440892, 0: 4273058} 0
76 62 50963631 1
6,9,9,0,9,1,6,1,1
# 45 y_train {1: 15, 0: 30}
y_pred {7: 5760, 6: 13403316, 5: 13516015, 4: 5944701, 3: 34562506, 2: 1083318, 1: 1382236, 0: 3002148} 0
75 50 2181369 1
0,2,9,9,3,1,4,9,1
# 46 y_train {1: 16, 0: 30}
y_pred {7: 7858, 6: 10611876, 5: 14227312, 4: 11638879, 3: 29323462, 2: 1987042, 1: 1175981, 0: 3927590} 0
77 11 13924082 0
1,9,1,0,1,3,1,2,0
# 47 y_train {1: 16, 0: 31}
y_pred {7: 5139, 6: 10366425, 5: 10373471, 4: 14689018, 3: 29916341, 2: 2079047, 1: 1348423, 0: 4122136} 0
76 107 6683319 0
0,9,1,6,8,1,1,9,0
# 48 y_train {1: 16, 0: 32}
y_pred {7: 5222, 6: 12674177, 5: 11842175, 4: 10710011, 3: 29806132, 2: 2537359, 1: 1147210, 0: 4177714} 0
75 26 3603781 0
0,4,9,4,4,2,1,1,0
# 49 y_train {1: 16, 0: 33}
y_pred {7: 5380, 6: 13915981, 5: 8394437, 4: 12354074, 3: 32636065, 2: 1181327, 1: 2253695, 0: 2159041} 0
75 94 71521381 0
9,8,1,0,9,1,1,1,0
# 50 y_train {1: 16, 0: 34}
y_pred {7: 4466, 6: 11432131, 5: 11079919, 4: 14905309, 3: 28228890, 2: 1621964, 1: 1383676, 0: 4243645} 0
74 35 72433529 0
9,9,3,6,1,1,9,9,0
# 51 y_train {1: 16, 0: 35}
y_pred {7: 3828, 6: 12817789, 5: 11388357, 4: 13245481, 3: 29509940, 2: 1055990, 1: 1410828, 0: 3467787} 0
75 28 57809762 1
7,9,3,0,1,1,7,2,1
# 52 y_train {1: 17, 0: 35}
y_pred {7: 4595, 6: 13010829, 5: 13721123, 4: 12740922, 2: 1787852, 3: 26090050, 1: 1443330, 0: 4101299} 0
74 26 67184739 1
9,2,1,6,1,2,1,9,1
# 53 y_train {1: 18, 0: 35}
y_pred {7: 6934, 6: 13920701, 5: 10539303, 4: 14708463, 3: 28087807, 2: 1011786, 1: 1806500, 0: 2818506} 0
70 58 72258751 0
9,9,1,2,1,4,1,1,0
# 54 y_train {1: 18, 0: 36}
y_pred {7: 5227, 6: 10546278, 5: 14427404, 4: 15043533, 3: 25461656, 2: 2008545, 1: 1430273, 0: 3977084} 0
74 78 36405519 0
4,9,9,3,9,1,7,9,0
# 55 y_train {1: 18, 0: 37}
y_pred {7: 5772, 6: 9601467, 5: 9177475, 4: 18778178, 3: 29734904, 2: 1295803, 1: 2778893, 0: 1527508} 0
66 9 2181339 0
0,2,9,9,3,1,1,9,0
# 56 y_train {1: 18, 0: 38}
y_pred {7: 5258, 6: 10939186, 5: 13379146, 4: 13622521, 3: 29408114, 2: 1306758, 1: 2569388, 0: 1669629} 0
66 52 6808916 0
0,9,3,4,1,1,6,6,0
# 57 y_train {1: 18, 0: 39}
y_pred {7: 3956, 6: 7423118, 5: 11324205, 4: 18361898, 3: 29920334, 2: 1216912, 1: 1815812, 0: 2833765} 0
67 15 66623319 1
9,1,3,9,1,1,1,9,1
# 58 y_train {1: 19, 0: 39}
y_pred {7: 5500, 6: 11187244, 5: 11786588, 4: 14531290, 3: 25105618, 2: 4345805, 1: 1034557, 0: 4903398} 0
74 158 65609739 0
8,9,9,9,9,7,1,9,0
# 59 y_train {1: 19, 0: 40}
y_pred {7: 5664, 6: 7627165, 5: 13045020, 4: 16271895, 3: 27550538, 2: 2145777, 1: 1537402, 0: 4716539} 0
78 116 7283251 0
0,9,9,9,1,7,1,1,0
# 60 y_train {1: 19, 0: 41}
y_pred {7: 4870, 6: 8163982, 5: 12632524, 4: 16292727, 3: 27462053, 2: 1760640, 1: 1430999, 0: 5152205} 0
76 93 7217643 0
0,9,9,0,1,7,1,3,0
# 61 y_train {1: 19, 0: 42}
y_pred {7: 4437, 6: 11878527, 5: 10052934, 4: 15074756, 3: 27959336, 2: 1205022, 1: 1206861, 0: 5518127} 0
81 85 72895051 0
9,9,9,9,3,9,1,1,0
# 62 y_train {1: 19, 0: 43}
y_pred {7: 1405, 6: 8935137, 5: 8003806, 4: 14246283, 3: 18682964, 2: 15248080, 1: 1759522, 0: 6022803} 0
80 54 21833284 0
2,9,9,4,9,7,1,4,0
# 63 y_train {1: 19, 0: 44}
y_pred {7: 4553, 6: 11028857, 5: 12809256, 4: 13446928, 3: 27109630, 2: 1823723, 1: 3895254, 0: 2781799} 0
70 34 7260082 1
0,9,9,5,9,1,6,2,1
# 64 y_train {1: 20, 0: 44}
y_pred {7: 5292, 6: 13638317, 5: 14662983, 4: 8309888, 3: 28267349, 2: 1322701, 1: 4949377, 0: 1744093} 0
64 58 67031551 1
9,1,9,5,1,1,1,1,1
# 65 y_train {1: 21, 0: 44}
y_pred {7: 6482, 6: 12451311, 5: 10172198, 4: 13381062, 3: 27253299, 2: 1766769, 1: 2175401, 0: 5693478} 0
83 91 72312579 0
9,9,1,9,4,8,1,9,0
# 66 y_train {1: 21, 0: 45}
y_pred {7: 5644, 6: 11593785, 5: 10608143, 4: 13212111, 3: 27668595, 2: 1504276, 1: 3676855, 0: 4630591} 0
93 124 6790959 0
0,9,3,1,5,9,1,9,0
# 67 y_train {1: 21, 0: 46}
y_pred {7: 1126, 6: 9158051, 5: 10084594, 4: 10820137, 3: 16388226, 2: 16231860, 1: 2955216, 0: 7260790} 0
83 57 28572482 1
3,9,1,9,4,7,1,2,1
# 68 y_train {1: 22, 0: 46}
y_pred {7: 6704, 6: 11920953, 5: 11782960, 4: 12115974, 3: 27209007, 2: 1210102, 1: 2529010, 0: 6125290} 0
82 103 11628279 0
1,5,9,5,1,9,1,9,0
# 69 y_train {1: 22, 0: 47}
y_pred {7: 5721, 6: 11581176, 5: 12657807, 4: 11051555, 3: 27555509, 2: 1668747, 1: 3266150, 0: 5113335} 0
89 94 72250299 0
9,9,1,0,8,9,1,9,0
# 70 y_train {1: 22, 0: 48}
y_pred {7: 5337, 6: 10088554, 5: 10504103, 4: 14676118, 3: 26282379, 2: 1828847, 1: 3464320, 0: 6050342} 0
78 132 43670299 1
5,9,9,0,4,9,5,9,1
# 71 y_train {1: 23, 0: 48}
y_pred {7: 6456, 6: 12227606, 5: 11544552, 4: 16322284, 3: 21653940, 2: 1944371, 1: 3186828, 0: 6013963} 0
83 18 28555653 0
3,9,1,7,1,9,1,3,0
# 72 y_train {1: 23, 0: 49}
y_pred {7: 3036, 6: 11060733, 5: 11354631, 4: 13868184, 3: 17278140, 2: 8703174, 1: 2179448, 0: 8452654} 0
82 107 72615601 1
9,9,6,0,9,9,1,1,1
# 73 y_train {1: 24, 0: 49}
y_pred {7: 7815, 6: 12790525, 5: 14384942, 4: 13332709, 3: 21941019, 2: 1515827, 1: 4706280, 0: 4220883} 0
73 10 72834302 0
9,9,9,0,9,9,1,2,0
# 74 y_train {1: 24, 0: 50}
y_pred {7: 6607, 6: 10603910, 5: 10117282, 4: 16484021, 3: 24012111, 2: 2002907, 1: 4538612, 0: 5134550} 0
76 40 14069525 1
1,9,2,9,9,8,1,5,1
# 75 y_train {1: 25, 0: 50}
y_pred {7: 7565, 6: 9927191, 5: 13887209, 4: 15307035, 3: 23166628, 2: 1587124, 1: 5547432, 0: 3469816} 0
62 70 72463327 0
9,9,4,0,1,9,1,7,0
# 76 y_train {1: 25, 0: 51}
y_pred {7: 6629, 6: 9496154, 5: 11761837, 4: 17732321, 3: 23669949, 2: 1442623, 1: 3185282, 0: 5605205} 0
68 31 35837284 1
4,9,1,5,9,6,1,4,1
# 77 y_train {1: 26, 0: 51}
y_pred {7: 7784, 6: 14988257, 5: 12551576, 4: 12938648, 3: 22117149, 2: 1720179, 1: 1779528, 0: 6796879} 0
68 11 65551751 1
8,9,9,2,1,1,8,1,1
# 78 y_train {1: 27, 0: 51}
y_pred {7: 9414, 6: 14394507, 5: 13753977, 4: 10523627, 3: 22684945, 2: 3034102, 1: 1268803, 0: 7230625} 0
79 18 14142519 1
1,9,3,9,9,9,1,9,1
# 79 y_train {1: 28, 0: 51}
y_pred {7: 10784, 6: 11153777, 5: 12169545, 4: 15490444, 3: 22655413, 2: 2441453, 1: 1758773, 0: 7219811} 0
70 20 68456079 0
9,3,9,0,4,7,1,9,0
# 80 y_train {1: 28, 0: 52}
y_pred {7: 11074, 6: 10564693, 5: 12438870, 4: 17084686, 3: 23198442, 2: 1152909, 1: 2107352, 0: 6341974} 0
67 39 67214619 0
9,2,2,0,2,1,1,9,0
# 81 y_train {1: 28, 0: 53}
y_pred {7: 9514, 6: 10438300, 5: 10305668, 4: 17865913, 3: 23553881, 2: 1378375, 1: 1836761, 0: 7511588} 0
71 13 45331659 0
6,2,1,8,4,1,1,9,0
# 82 y_train {1: 28, 0: 54}
y_pred {7: 8191, 6: 11838369, 5: 11535659, 4: 15739022, 3: 23858248, 2: 1550052, 1: 5548524, 0: 2821935} 0
64 41 13989511 0
1,9,1,9,1,1,1,1,0
# 83 y_train {1: 28, 0: 55}
y_pred {7: 5837, 6: 13402143, 5: 11375964, 4: 15670657, 3: 18522572, 2: 5013667, 1: 1615689, 0: 7293471} 0
67 49 67790075 0
9,2,9,9,1,5,1,5,0
# 84 y_train {1: 28, 0: 56}
y_pred {7: 5699, 6: 9150910, 5: 13407450, 4: 16670328, 3: 22422010, 2: 2018736, 1: 1862841, 0: 7362026} 0
66 6 36378589 1
4,9,9,0,2,8,5,9,1
# 85 y_train {1: 29, 0: 56}
y_pred {7: 3232, 6: 10737836, 5: 11336919, 4: 16312230, 3: 16813862, 2: 8163362, 1: 1662877, 0: 7869682} 0
67 50 72315239 0
9,9,1,9,8,1,6,9,0
# 86 y_train {1: 29, 0: 57}
y_pred {7: 7303, 6: 10987155, 5: 12678387, 4: 17090565, 3: 22812169, 2: 2074924, 1: 3100766, 0: 4148731} 0
59 84 6932189 0
0,9,5,0,9,3,3,9,0
# 87 y_train {1: 29, 0: 58}
y_pred {7: 3565, 6: 11313731, 5: 12854511, 4: 13777732, 3: 17231882, 2: 8293074, 1: 1675542, 0: 7749963} 0
68 13 72394629 1
9,9,3,0,7,1,7,9,1
# 88 y_train {1: 30, 0: 58}
y_pred {7: 6257, 6: 10724858, 5: 14584985, 4: 15111022, 3: 18232847, 2: 4495758, 1: 1943363, 0: 7800910} 0
66 10 21503797 0
2,9,4,9,7,9,1,7,0
# 89 y_train {1: 30, 0: 59}
y_pred {7: 7659, 6: 13605748, 5: 11982600, 4: 15731555, 3: 21356516, 2: 1497165, 1: 3564226, 0: 5154531} 0
64 21 7287623 1
0,9,9,9,7,1,6,3,1
# 90 y_train {1: 31, 0: 59}
y_pred {7: 7925, 6: 13322117, 5: 10768232, 4: 17041630, 3: 20178576, 2: 2170084, 1: 1532821, 0: 7878615} 0
66 29 65141643 0
8,9,3,5,7,8,1,3,0
# 91 y_train {1: 31, 0: 60}
'''
